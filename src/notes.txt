Implementation Notes


Camera
This one took me a long time to wrap my head around. In the end, I found the chapter on transformation matrices in Marschner and Shirley's "Fundamentals of Computer Graphics" to really help drive home these concepts. The fundamental problem that I had was understanding the function of the matrices and the conceptual essence of local space, world space, and screen space. Defining and working with arbitrary coordinate systems didn't come intuitively to me, but I think I've finally gotten a grasp on it. It's honestly fascinating how objects in some arbitrary coordinate space really only exist in relation to other objects/some arbitrarily defined origin. I look forward to exploring these ideas some more. 

As it stands now, my camera architecture consists of a dedicated Camera class (camera.hpp and camera.cpp) and a CameraNode class (camera_node.hpp and camera_node.cpp). Cameras define and store a center point, a width, and a height, and they provide an interface for converting from world to screen space, as well as provide functions for movement and scaling. CameraNode objects provide generic node behavior, store a Camera object, and provide a getter for that Camera. In my current implementation, SceneStates have been updated to include a pointer to the active CameraNode. This is how I give geometry nodes access to cameras, which are used to perform world to screen transformations on geometry node objects, but I am interested if there is a more straightforward/more architecturally sound way to structure this. 

My revised scene places a CameraNode near the top of the scene graph hierarchy. As the game executes, the CameraNode's update() function listens for WASD and mouse wheel input to adjust position and scaling. On calls to draw(), the CameraNode sets itself as the active camera and pushes to the matrix stack before drawing its children. GeometryNode objects first derive their position in world space and then use the active camera stored in SceneState to derive their position in screen space. Screen space coordinates are then used to define the SDL_FPoints that are used in rendering geometry objects.

IO Handling
For this one, I implemented a three-layer input system architecture to decouple raw device events from game logic. The first layer sits in event.hpp and event.cpp and captures raw device events through SDL. The second layer (input_interpreter.hpp and input_interpreter.cpp) translates these device-specific events into device-agnostic game actions that are defined in game_action.hpp. The interpreter itself simply provides a function to interpret game actions from raw input. 

The third layer manages the IO pipeline and is contained within my original IoHandler class (io_handler.hpp and io_handler.cpp). This class now stores an interpreter object and collections of raw SDL input and game actions. The handler's update() function gets new raw input and translates those into game actions. It's the "central hub" of input processing and provides an interface for nodes within the scene graph to get input data that can be used to execute game logic. SceneState objects now also contain pointers to an IoHandler object. 

From the collection of game actions returned by the IO handler, nodes within the scene graph can use their update() functions to listen for certain input and take action based on those inputs. For example, my CameraNode implementation listens for WASD and scroll wheel inputs and modifies the camera based on the input received. 


